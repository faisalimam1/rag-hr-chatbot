# RAG HR Chatbot

This project is a **Retrieval-Augmented Generation (RAG) chatbot** that answers employee queries based on an HR Policy document.  
It demonstrates how HR teams can deploy an internal AI assistant that retrieves policy information and generates concise, citation-backed answers.

---

## ğŸ“Œ Features
- **PDF ingestion**: extract and clean HR policy text  
- **Chunking**: split into overlapping chunks for semantic search  
- **Embeddings + FAISS**: vector index for fast retrieval  
- **Re-ranking**: hybrid approach (BM25 + cosine similarity) for accuracy  
- **Backend**: FastAPI `/query` endpoint (answer, sources, latency)  
- **Frontend**: Streamlit chat-like interface  
- **Caching**: in-memory LRU cache (with optional Redis)  
- **Dockerized**: single `docker-compose up` runs everything  

---

## ğŸ—‚ Project Structure
rag-hr-chatbot/
â”œâ”€ data/
â”‚ â”œâ”€ hr_policy.pdf # Input HR Policy
â”‚ â””â”€ extracted_text/ # Intermediate JSON
â”œâ”€ ingestion/ # Extraction + cleaning + chunking
â”œâ”€ embeddings/ # Embeddings (OpenAI / sentence-transformers)
â”œâ”€ index/ # FAISS index utilities
â”œâ”€ reranker/ # BM25 + cosine reranker
â”œâ”€ backend/ # FastAPI backend + cache
â”œâ”€ frontend/ # Streamlit UI
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”œâ”€ requirements.txt
â””â”€ README.md

yaml
Copy code

---

## âš¡ Quickstart

### Local Run
```bash
# 1. Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate   # Linux/macOS
.venv\Scripts\activate      # Windows

# 2. Install dependencies
pip install -r requirements.txt
Add your HR policy at:

bash
Copy code
data/hr_policy.pdf
Build the index:

bash
Copy code
# Extract text
python ingestion/extract_text.py --pdf data/hr_policy.pdf --out data/extracted_text/hr_policy_pages.json

# Chunk text
python ingestion/chunker.py --pages data/extracted_text/hr_policy_pages.json --out data/extracted_text/chunks.json

# Build FAISS index
python index/build_faiss.py --chunks data/extracted_text/chunks.json --out_dir index
Run services:

bash
Copy code
# Backend
uvicorn backend.api:app --reload   # â†’ http://localhost:8000/docs

# Frontend
streamlit run frontend/app.py      # â†’ http://localhost:8501
Docker (Recommended)
bash
Copy code
docker-compose up --build
Backend â†’ http://localhost:8000

Frontend â†’ http://localhost:8501

ğŸ”‘ Configuration
OpenAI API Key (optional, improves quality):

bash
Copy code
export OPENAI_API_KEY="your_api_key"
Embeddings: text-embedding-3-small

LLM: gpt-4o-mini

Offline mode: uses sentence-transformers + deterministic summarizer if no API key is set.

ğŸ¯ Demo Scenarios
â€œHow many earned leaves do I get?â€ â†’ 18 per year (with citation)

â€œWhat is the maternity leave policy?â€ â†’ 26 weeks if employed >1 year (with citation)

â€œCan I get 1 year of paternity leave?â€ â†’ Graceful fallback answer

Repeat queries â†’ Demonstrates cache (faster response)

ğŸ“Š Tech Stack
Python 3.11

FAISS (vector search)

rank_bm25 (lexical reranker)

FastAPI (backend)

Streamlit (frontend)

Docker + docker-compose

âœ… Notes
Keep /data private (contains HR documents)

Add authentication for production deployments

Ensure no sensitive data (PII) is embedded

âœ¨ Recruiter Value
This project highlights my ability to:

Ingest & preprocess unstructured data (PDF policies)

Build retrieval pipelines with FAISS + reranking

Integrate LLMs for grounded, reliable answers

Deliver a full-stack solution (backend + frontend + Docker)

Balance demo simplicity with production-readiness

ğŸ”— GitHub Repo: github.com/faisalimam1/rag-hr-chatbot
